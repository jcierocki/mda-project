{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameters Holt Winters Model",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eoVZQxxAYLn4"
      },
      "outputs": [],
      "source": [
        "# grid search ets models\n",
        "from math import sqrt\n",
        "from multiprocessing import cpu_count\n",
        "from joblib import Parallel\n",
        "from joblib import delayed\n",
        "from warnings import catch_warnings\n",
        "from warnings import filterwarnings\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from pandas import read_csv\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas.util.testing as tm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-step Holt Winterâ€™s Exponential Smoothing forecast\n",
        "def exp_smoothing_forecast(history, config):\n",
        "\tt,d,s,p,b,r = config\n",
        "\t# define model\n",
        "\thistory = array(history)\n",
        "\tmodel = ExponentialSmoothing(history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
        "\t# fit model\n",
        "\tmodel_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
        "\t# make one step forecast\n",
        "\tyhat = model_fit.predict(len(history), len(history))\n",
        "\treturn yhat[0]\n",
        " \n",
        "# root mean squared error or rmse\n",
        "def measure_rmse(actual, predicted):\n",
        "\treturn sqrt(mean_squared_error(actual, predicted))\n",
        " \n",
        "# split a univariate dataset into train/test sets\n",
        "def train_test_split(data, n_test):\n",
        "\treturn data[:-n_test], data[-n_test:]\n",
        " \n",
        "# walk-forward validation for univariate data\n",
        "def walk_forward_validation(data, n_test, cfg):\n",
        "\tpredictions = list()\n",
        "\t# split dataset\n",
        "\ttrain, test = train_test_split(data, n_test)\n",
        "\t# seed history with training dataset\n",
        "\thistory = [x for x in train]\n",
        "\t# step over each time-step in the test set\n",
        "\tfor i in range(len(test)):\n",
        "\t\t# fit model and make forecast for history\n",
        "\t\tyhat = exp_smoothing_forecast(history, cfg)\n",
        "\t\t# store forecast in list of predictions\n",
        "\t\tpredictions.append(yhat)\n",
        "\t\t# add actual observation to history for the next loop\n",
        "\t\thistory.append(test[i])\n",
        "\t# estimate prediction error\n",
        "\terror = measure_rmse(test, predictions)\n",
        "\treturn error\n",
        " \n",
        "# score a model, return None on failure\n",
        "def score_model(data, n_test, cfg, debug=False):\n",
        "\tresult = None\n",
        "\t# convert config to a key\n",
        "\tkey = str(cfg)\n",
        "\t# show all warnings and fail on exception if debugging\n",
        "\tif debug:\n",
        "\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
        "\telse:\n",
        "\t\t# one failure during model validation suggests an unstable config\n",
        "\t\ttry:\n",
        "\t\t\t# never show warnings when grid searching, too noisy\n",
        "\t\t\twith catch_warnings():\n",
        "\t\t\t\tfilterwarnings(\"ignore\")\n",
        "\t\t\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
        "\t\texcept:\n",
        "\t\t\terror = None\n",
        "\t# check for an interesting result\n",
        "\tif result is not None:\n",
        "\t\tprint(' > Model[%s] %.3f' % (key, result))\n",
        "\treturn (key, result)\n",
        " \n",
        "# grid search configs\n",
        "def grid_search(data, cfg_list, n_test, parallel=True):\n",
        "\tscores = None\n",
        "\tif parallel:\n",
        "\t\t# execute configs in parallel\n",
        "\t\texecutor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')\n",
        "\t\ttasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)\n",
        "\t\tscores = executor(tasks)\n",
        "\telse:\n",
        "\t\tscores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
        "\t# remove empty results\n",
        "\tscores = [r for r in scores if r[1] != None]\n",
        "\t# sort configs by error, asc\n",
        "\tscores.sort(key=lambda tup: tup[1])\n",
        "\treturn scores\n",
        " \n",
        "# create a set of exponential smoothing configs to try\n",
        "def exp_smoothing_configs(seasonal=[None]):\n",
        "\tmodels = list()\n",
        "\t# define config lists\n",
        "\tt_params = ['add', 'mul', None]\n",
        "\td_params = [True, False]\n",
        "\ts_params = ['add', 'mul', None]\n",
        "\tp_params = seasonal\n",
        "\tb_params = [True, False]\n",
        "\tr_params = [True, False]\n",
        "\t# create config instances\n",
        "\tfor t in t_params:\n",
        "\t\tfor d in d_params:\n",
        "\t\t\tfor s in s_params:\n",
        "\t\t\t\tfor p in p_params:\n",
        "\t\t\t\t\tfor b in b_params:\n",
        "\t\t\t\t\t\tfor r in r_params:\n",
        "\t\t\t\t\t\t\tcfg = [t,d,s,p,b,r]\n",
        "\t\t\t\t\t\t\tmodels.append(cfg)\n",
        "\treturn models\n",
        " \n"
      ],
      "metadata": {
        "id": "3r9ovyJrYWxn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Allemand/county_daily.csv'\n",
        "data = pd.read_csv(path, parse_dates=True)\n",
        "data.head()  \n",
        "df3 = data.groupby(\"date\").agg(list) # dataframe with date as index and each columns contain list"
      ],
      "metadata": {
        "id": "wF1ttWtdZ1fH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Number of cases"
      ],
      "metadata": {
        "id": "qk4bRxzcKQ4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3['cases'][0]\n",
        "total_cases = []\n",
        "for i in range(852) :\n",
        "    total_cases.append(sum(df3['cases'][i]))\n",
        "\n",
        "df3['total_cases'] = total_cases\n",
        "for i in range(852) :\n",
        "    df3.loc[df3['total_cases'] == 0, 'B'] = 0.00001\n",
        "    df3.loc[df3['total_cases'] < 0, 'B'] = 0.00001\n",
        "    df3.loc[df3['total_cases'] > 0, 'B'] = df3['total_cases']\n",
        "\n",
        "df3.index.freq='D'\n",
        "\n",
        "data2 = []\n",
        "for i in range(len(df3['B'])) : \n",
        "  data2.append(np.array(df3['B'][i]))"
      ],
      "metadata": {
        "id": "XmWInviY2o1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\t# load dataset\n",
        "\tdata = np.array(data2)\n",
        "\t# data split\n",
        "\tn_test = 170\n",
        "\t# model configs\n",
        "\tcfg_list = exp_smoothing_configs()\n",
        "\t# grid search\n",
        "\tscores = grid_search(data, cfg_list, n_test)\n",
        "\tprint('done')\n",
        "\t# list top 3 configs\n",
        "\tfor cfg, error in scores[:3]:\n",
        "\t\tprint(cfg, error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdJVFTgLYa3A",
        "outputId": "0f7c5978-887a-4abd-a05c-d5dd85e0e8c5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Model[['add', True, None, None, False, True]] 174437.200\n",
            " > Model[['add', True, None, None, True, True]] 170165.866\n",
            " > Model[['add', True, None, None, False, False]] 174274.146\n",
            " > Model[['add', True, None, None, True, False]] 170373.397\n",
            " > Model[['add', False, None, None, True, True]] 173611.810\n",
            " > Model[['add', False, None, None, True, False]] 173545.444\n",
            " > Model[['add', False, None, None, False, True]] 178843.248\n",
            " > Model[['add', False, None, None, False, False]] 178631.762\n",
            " > Model[[None, False, None, None, True, True]] 177528.426\n",
            " > Model[[None, False, None, None, False, True]] 177658.725\n",
            " > Model[[None, False, None, None, True, False]] 178179.608\n",
            " > Model[[None, False, None, None, False, False]] 177498.829\n",
            "done\n",
            "['add', True, None, None, True, True] 170165.8657395654\n",
            "['add', True, None, None, True, False] 170373.39672161834\n",
            "['add', False, None, None, True, False] 173545.44398144458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Number of deaths"
      ],
      "metadata": {
        "id": "qIyg3pe9KWhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3['deaths'][0]\n",
        "total_deaths = []\n",
        "for i in range(852) :\n",
        "    total_deaths.append(sum(df3['deaths'][i]))\n",
        "\n",
        "df3['total_deaths'] = total_deaths\n",
        "\n",
        "df3.loc[df3['total_deaths'] == 0, 'total_deaths'] = 0.00001\n",
        "df3.loc[df3['total_deaths'] < 0, 'total_deaths'] = 0.00001\n",
        "\n",
        "\n",
        "df3.index.freq='D'\n",
        "\n",
        "data3 = []\n",
        "for i in range(len(df3['total_deaths'])) : \n",
        "  data3.append(np.array(df3['total_deaths'][i]))"
      ],
      "metadata": {
        "id": "7kZjSLye0OUF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\t# load dataset\n",
        "\tdata3 = np.array(data3)\n",
        "\t# data split\n",
        "\tn_test = 170\n",
        "\t# model configs\n",
        "\tcfg_list = exp_smoothing_configs()\n",
        "\t# grid search\n",
        "\tscores = grid_search(data3, cfg_list, n_test)\n",
        "\tprint('done')\n",
        "\t# list top 3 configs\n",
        "\tfor cfg, error in scores[:3]:\n",
        "\t\tprint(cfg, error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pNQg3qC06oA",
        "outputId": "46fb9782-65ca-4def-dc78-35ccec40bd98"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Model[['add', True, None, None, False, True]] 1057.055\n",
            " > Model[['add', True, None, None, False, False]] 1056.513\n",
            " > Model[['add', True, None, None, True, False]] 1074.802\n",
            " > Model[['add', False, None, None, True, False]] 1347.648\n",
            " > Model[['add', False, None, None, False, True]] 1059.704\n",
            " > Model[['add', False, None, None, False, False]] 1059.709\n",
            " > Model[[None, False, None, None, True, True]] 1081.052\n",
            " > Model[[None, False, None, None, True, False]] 1097.050\n",
            " > Model[[None, False, None, None, False, True]] 1059.847\n",
            " > Model[[None, False, None, None, False, False]] 1058.830\n",
            "done\n",
            "['add', True, None, None, False, False] 1056.5129628579614\n",
            "['add', True, None, None, False, True] 1057.0551615192633\n",
            "[None, False, None, None, False, False] 1058.8302764543414\n"
          ]
        }
      ]
    }
  ]
}